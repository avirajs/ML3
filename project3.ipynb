{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Preparation and Overview (30 points total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [20 points] Explain the task and what business-case or use-case it is designed to solve (or designed to investigate). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detail exactly what the classification task is and what parties would be interested in the results. For example, would the model be deployed or use mostly for offline analysis? \n",
    "\n",
    "Detail exactly what the classification task is and what parties would be interested in the results. For example, would the model be deployed or use mostly for offline analysis? \n",
    "\n",
    "# Business Understanding\n",
    "\n",
    "This data set is from The Department of Transportation’s Bureau of Transportation Statistics regarding the On Time Performance of domestic flights flying from the DFW airport from January to March of this year. Since the volume of the original data is so large, we decided to only look at flights from DFW to ORD (Chicago O'Hare) for our model. \n",
    "\n",
    "When booking flights for a trip, there are often many different airlines and times of day to choose from. Our classification task is to predict the departure delay group (how long the flight is delayed divided into 14 groups of 15 minute intervals ranging from <-15 minutes (flight is more than 15 minutes early) to >= 180 minutes) for each flight based on the Month, Day of Flight, Day of the Week, Departure Time, Airline and How long a flight was in the air **need to change. The end goal of analysis on our dataset is to be able to understand for an origin and a destination, in our case DFW to ORD, when is the best time to fly and with what airline in order to minimize departure delays when booking a trip. \n",
    "\n",
    "Our model can be applied to other origin and destination cities???? Since departure delays are highly varied by factor scaled up by train the model on different cities NOT SURE THAT makes sense\n",
    "\n",
    "# Who would benefit\n",
    "https://www.dallasnews.com/business/airlines/2018/07/11/airlineroutes-generate-cash-north-texas-top-10\n",
    "\n",
    "According to air travel intelligence company, OAG, from April 2017 to March 2018 DFW to ORD was DFW’s second highest grossing route, bringing in $358.4 million in revenue. Thus it is in the airlines best interest to minimize departure delay and maximize customer satisfaction on this route. Although small delays are inevitable, airlines that fly from DFW could use this analysis to help them see how they stack up to their competitors in terms of delay on this route and to help them better schedule their employees in order to account for probable delays. For example, during times when there is a high likelihood of a long delay they could have more gate and travel agent staff available.\n",
    "\n",
    "\n",
    "Businesses who send employees on business trips and people taking personal trips flying from DFW to ORD would benefit from this analysis. If a flight for a business trip gets delayed or cancelled, the company loses money as hours of the client or employee's time are wasted as a result. Additionally, many people get a very limited time for vacation and personal trips. A long delay or cancellation can cause them to lose valuable time at their destination or with their families. Using this analysis a person or company can try to schedule their flights to minimize likelihood of experiencing delays when flying from DFW. If a person has to fly during a time or with an airline with a likelihood of a long delay, they can use this analysis to help them plan accordingly and be sure to build in flexibility due to delays when planning their schedules.\n",
    "\n",
    "\n",
    "\n",
    "# Model Performance\n",
    "In order to be considered a useful model, the model will need to be able to accurately predict the entire dataset from a model created from the DFW subsample. ?\n",
    "\n",
    "Our model would most likely be used for offline analysis by the airlines, businesses, and customers planning a trip.\n",
    "\n",
    "For businesses and people using this model to try and plan their schedules when taking a personal or business trip a number of false negatives (where a flight is predicted to have a large delay but is not delayed) would not be too much of an issue, but a large number of false positives (where a flight is predicted to be early or have little or no delay but is delayed) would be problematic. Although some delays are unavoidable, it is not ethical or useful to the customer to have a large number of false positives. Because of this, our model would have to have a low rate  %%?? of false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5 points] (mostly the same processes as from previous labs) Define and prepare your class variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "Initial Dataset:\n",
    "* month (the day of the week of the flight) -----------------------> ordinal\n",
    "* dayofmonth (the day of the week of the flight) -----------------------> ordinal\n",
    "* dayofweek (the day of the week of the flight) -----------------------> ordinal\n",
    "* airline (the airline of the flight)--------------------------------> nominal\n",
    "* Origin (origin airport code of the flight)-------------------------> nominal\n",
    "* Dest (destination airport code of the flight)----------------------> nominal\n",
    "* DepTime (departure time of the flight)-----------------------------> ratio\n",
    "* DepDelay (delay of the flight departure in minutes)----------------> interval\n",
    "* DepDelayGroup (delay of the flight departure grouped by minutes)---> ordinal\n",
    "* DTimeBlk (delay of the flight grouped by hours)--------------------> ordinal\n",
    "* ActualElapsedTime (flight time in the air)-------------------------> ratio\n",
    "* Distance (distance the flight travelled)---------------------------> interval\n",
    "* DistGroup (distance the flight travelled grouped by miles----------> ordinal\n",
    "\n",
    "Final Dataset: \n",
    "* month (the day of the week of the flight) -----------------------> int\n",
    "* dayofmonth (the day of the week of the flight) -----------------------> int\n",
    "* dayofweek (the day of the week of the flight) -----------------------> int\n",
    "* airline (the airline of the flight)--------------------------------> one-hot encoded\n",
    "* DepTime (departure time of the flight)-----------------------------> float\n",
    "* DepDelayGroup (delay of the flight departure grouped by minutes)---> int\n",
    "* ActualElapsedTime (flight time in the air)-------------------------> float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [5 points] Divide you data into training and testing data using an 80% training and 20% testing split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cross validation modules that are part of scikit-learn. Argue \"for\" or \"against\" splitting your data using an 80/20 split. That is, why is the 80/20 split appropriate (or not) for your dataset?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling (50 points total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The implementation of logistic regression must be written only from the examples given to you by the instructor. No credit will be assigned to teams that copy implementations from another source, regardless of if the code is properly cited. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [20 points] Create a custom, one-versus-all logistic regression classifier using numpy and scipy to optimize. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use object oriented conventions identical to scikit-learn. You should start with the template developed by the instructor in the course. You should add the following functionality to the logistic regression classifier:Ability to choose optimization technique when class is instantiated: either steepest descent, stochastic gradient descent, or Newton's method.  Update the gradient calculation to include a customizable regularization term (either using no regularization, L1 regularization, L2 regularization, or both L1 and L2 regularization). Associate a cost with the regularization term, \"C\", that can be adjusted when the class is instantiated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [15 points] Train your classifier to achieve good generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " That is, adjust the optimization technique and the value of the regularization term \"C\" to achieve the best performance on your test set. Visualize the performance of the classifier versus the parameters you investigated. Is your method of selecting parameters justified? That is, do you think there is any \"data snooping\" involved with this method of selecting parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [15 points] Compare the performance of your \"best\" logistic regression optimization procedure to the procedure used in scikit-learn. Visualize the performance differences in terms of training time and classification performance. Discuss the results. \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deployment (10 points total)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which implementation of logistic regression would you advise be used in a deployed machine learning model, your implementation or scikit-learn (or other third party)? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exceptional Work (10 points total)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have free reign to provide additional analyses. One idea: Update the code to use either \"one-versus-all\" or \"one-versus-one\" extensions of binary to multi-class classification. \n",
    "        One idea (required for 7000 level students): Implement an optimization technique for logistic regression using mean square error as your objective function (instead of binary entropy). Your solution should be able to solve the binary logistic regression problem in one gradient update step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
